= Buffy for engineers

== What to expect from this document

This document is an introduction to what we are doing with as part of our Buffy
project. In general, this document should be an intro level document that
assumes experience with computers but limited experience with distributed
systems. Herein, we highlight issues that we are hoping to solve.

== The Data Processing Problem

Business today are producing more and more data. Many are accumlating more data,
hoping to find a use for it. People recognize that there could be great value
in the data they are accumulating. Falling storage prices now make it reasonable
for a business to retain a large amount of the data it creates even if there is
no immediate value. The tools used to process this data are still in their
infancy. There are a few tools that make great exemplars of various ways
businesses currently process data.

=== 3 Categories of data processing tools

Roughly, they fall into 3 categories: batch, micro-batch, and stream processing.

==== Batch Processing

Batch systems are best exemplified by Hadoop. At this point, if there is one
data processing system that people are likely to have heard of, its Hadoop. The
question  “How is X different than Hadoop?” is still so common that in the
distributed systems, data processing space it is often deployed for ridiculous
intent “How is that grilled cheese sandwich different than Hadoop?” The majority
of our existing data processing is done using batch systems of various sizes and
flavors. What they have in common is that they take a predetermined set of data,
that is, a batch, and operate on it for some period of time; usually measured in
hours or days before finally returning results. They can help us learn from
large amounts of data but the time to learn can be slow.

==== Micro-batch processing

Micro-batch systems are best exemplified by Spark Streaming. A micro-batch
system still operates on batches of data a time, but they are small. Perhaps
1,000 or 100,000 records. Our time to process is generally much lower, often
measured in minutes rather than hours.

==== Stream processing

Finally, we come to stream processing. Stream processing acts on an unbounded
stream of data rather than a bounded set like a batch system does. A stream
processor is continually ingesting new data (a stream) and delivering results.
We say the stream is unbounded because unless explicitly stopped, stream
processors have no defined end. They run and process data until they are shut
down. Stream processors can help us learn about data in timelines that are
measured in milliseconds and seconds rather than hours.

Stream processing has a long history but has recently popped back into the
computing public’s general knowledge with growing interest in Apache Storm as
well as some other projects such as Samza, S3, Amazon Lambda and commercial
offerings like Streambase.

=== Processing Architectures

Nathan Marz, the original developer of Storm, wrote a book called “Big Data:
Principles and best practices of scalable realtime data systems” that introduces
what he calls “The Lambda Architecture” as a way to address our data processing
problem. In response to the introduction of the Lambda Architecture, Jay Kreps
introduced the idea of the Kappa Architecture. Each has a different take on how
to integrate stream processing into an overall data handling.

==== The Lambda Architecture

The core idea of the lambda architecture is that you have a slower batch layer
that runs at daily pace which provides you accuracy and you supplement that with
a less accurate streaming layer that provides less accurate more up to date
values. You can then stitch these values together to get a view into what is
going on within your system. This means that you have to operate more than 1
system at a time, the streaming system and the batch system. In addition, to
this operational complexity, you also have the difficulty of stitching the
results together. The lambda architecture can be appealing if you have an
existing batch system as you can then work out how to integrate more up to date
results from a streaming system that you add-on to your existing architecture.

==== Kappa Architecture

The kappa architecture was formulated in opposition to the lambda architecture
by Jay Kreps and fellow LinkedIn employees. Its approach is exemplified by the
systems they have built, particularly Apache Samza.

The key point of the kappa architecture is:

 We only need to take on the operational complexity of the lambda architecture
 because our stream processor isn’t capable of being both fast and accurate. If
 we can create a better stream processor then all our data processing can be
 stream based.

The Lambda Architecture means running at least two data processing systems; at a
cost of vastly increased operational complexity. The Kappa Architecture posits
that rather than taking on that cost, we should look to improve the faults in
our stream processing systems (like accuracy) that lead us to consider the
Lambda Architecture in the first place.

== Stream processing: The Hard parts

What do most existing frameworks provide. What do they leave out. State
processing is hard. Idempotent processing is hard. Roll your own is difficult
to get right.

Popular stream processing frameworks such as Storm handle the easiest parts of
the problem and leave the programmer holding the bag for the difficult parts.
Getting high throughput or low latency isn’t particularly hard.

However, providing “exactly once” semantics is. Exactly once is a holy grail of
sorts in stream processing. Ideally, we want each message to be delivered and
processed once and only once. However, in the face of failures, that isn’t
possible. Imagine Alice and Bob talking over an unreliable connection. Each
time one of them says something, they wait for the other to respond “Ok”. This
“Ok” acts as an acknowledgement that the message was received. If Alice sends a
message to Bob and Bob doesn’t respond, there’s a wide variety of things that
could have happened. Bob might not have received the message, Bob might have
received but his acknowledgement was lost and so on and so forth. The important
idea here is we can never be sure when we don’t get that acknowledgement whether
Bob got the message.

The standard solution to this is “at least once” messaging: we keep resending
the message until we get at least one acknowledgement. This works great for
making sure something gets done but isn’t great for accuracy. It’s quite
possible Bob might get a message more than once and undertake the same action
in response more than once. If Bob is maintaining a count of some sort and the
messages are “add 1”, “add 5”, and “subtract 2”, then with at least once
messaging he is going to end up with an inaccurate value. To address this, we
need to introduce idempotence. Idempotence ensures that when Alice sends the
message “add 2” (with some way of uniquely identifying it), Bob disregards the
message if he has already seen it. That is, we process each message only once,
no matter how many times we receive it. Idempotence really helps with accuracy.
However, it’s complicated and easy to get wrong.

Most current systems leave the developer holding the bag for accuracy.
Programmers have to roll their own idempotence. We envision a system that is
built on top of idempotent data structures that allow for the same operation to
happen more than once (thereby ensuring message processing) without forcing the
programmer to be a distributed systems expert. Idempotent processing is hard.
State management is hard.

== Our Solution: Buffy

The Sendence solution, our internal project is code named Buffy. It's important
to understand what our goals are at a high level. This is what we are working
towards. How we get there is less important than reaching our goals and how we
balance between the competing interests of those goals.

=== Buffy: the idea

Buffy is a fast, accurate, reliable and scalable stream processing platform that
allows the easy development and implementation of real-time applications.

Buffy is Fast::
Processing latencies are measured in nanoseconds and have compact distributions.

Buffy is Accurate::
Exactly-once processing is guaranteed by using idempotent data structures and processing logic.

Buffy is Reliable::
Monitors itself for issues and anomalies and self-heals.

Buffy is Scalable::
Horizontally scalable on commodity hardware.

Features::
* Data streams from any source can be ingested
* Data processing applications are easily defined
* Data connectors allow data to stream to external sources
* Long lived stable and versioned API to the processing infrastructure
* Tracing and sampling of processing
* Able to generate synthetic streams to reproduce production failures (as an automatic consequence of any failure occurring):
* Have predictable and compact latency distributions

==== What do we mean by...

Fast::
High Throughput:::
Processing rates for Buffy should be measured in the millions of messages per
second.
Low Latency:::
Buffy will allow for low latency use cases. We measure of latencies in
nanoseconds not milliseconds. Our goal is for Buffy and its various features to
add as little overhead as possible. By keeping our overhead low, we hope to
enable a new generation of applications that are currently only available via
custom development. This means that features such as message delivery guarantees
can’t come with the high overheads.
+
Saying low latency is all well and good but, what
is our measurement for low latency? 95p? 99p? We haven’t come up with a hard
determination of that. However, we know that we want to have soft real time
latency guarantees such that tail latencies are within striking range of our
targets rather than the hockey stick latencies that one sees from many
distributed systems.

Accurate::
Exactly-once delivery in a distributed system is impossible. We have two options:
At-most-once delivery and At-least-once delivery.
+
In our worst case scenario, at-most-once delivery means that we might never
process some message. At-least-once delivery worst case is that we might
process a message more than once. Either way, this is a disaster if we want to
be as accurate as possible. You can achieve the semantics of exactly-once
processing in an at-least-once system by doing idempotent processing of
messages. That is, processing a message more than once, has no more of an
impact that processing it once.
+
Buffy provides idempotent data structures that allows us to provide
at-least-once delivery while maintaining exactly-once semantics.

Reliable::
Guaranteed message processing + self healing.

Scalable::
To keep up with ever expanding data processing needs, Buffy adopts a scale out
approach. Throughput capacity can be added at any time by adding additional
nodes to an existing Buffy cluster.

==== Trade-offs: It’s always about trade-offs

Those are some pretty impressive goals we’ve set for Buffy; calling it the holy
grail of stream processing wouldn’t be out of line. Is this even possible? Yes,
but there will be trade-offs.

Providing accuracy means adding overhead that will impact on speed. Providing
reliability and scalability via a scale out design means adding latency
overheads. Optimizing for throughput can negatively impact latency and
vice-versa. Each streaming use case will want to a different balance and will
have a different tolerance for different trade-offs. Wherever possible, we want
to allow the system operator the power to influence those trade-offs.

This could be at the use case level where you can sacrifice reliability for
speed by lowering the number of replicas you have of your data in order to gain
speed. Or it could be at the platform level where you can tune shared buffers
and optimize for throughput rather than latency. The important thing is that we
allow the operator to make those choices. When we dive into specific features of
Buffy later in this document, we will discuss ways that we can make each feature
tunable.

=== Buffy: the components

Let’s quickly touch on each of the core components of Buffy and we what get from
them. We will discuss each in more depth later. What’s important now it to
understand the role each plays in the larger system.

Clustered solution::
Provide resiliency and scalability by creating a scale out clustered platform.

In memory computing::
All platform data will be stored in memory to lower latency and increase
throughput by not having to make trips to external systems in order to get data
needed for processing.

Idempotent data-structures::
Data structures such as CRDTs that can be replicated and accept writes at any
replica can help increase platform throughput and ease state management and
correctness in an at-least-once system.

Intelligent topology layout::
We need to colocate computation with the data it uses on the same node to
prevent having to fetch needed data from other nodes in the cluster.

=== Buffy: the architecture

Earlier we said that the hardest part of stream processing is state management
and idempotent processing. We further said that Buffy would solve this for
programmer in a seamless fashion. Given that we are making this a core value
proposition of Buffy, it makes sense to start our discussion of Buffy with how
it addresses these issues.

At the heart of Buffy is a synthesis of some ideas that have been around in
computer science for a long time combined together with some rather new ones.

==== Buffy as dataflow

 Dataflow is a software architecture based on the idea that changing the value
 of a variable should automatically force recalculation of the values of
 variables which depend on its value.
 <from https://en.wikipedia.org/wiki/Dataflow>

Buffy provides reusable idempotent data structures connected together using
functions. Functions can subscribe to changes to specific idempotent data
structures and can then in turn update other (or the same) idempotent data
structures to continue the cycle. Imagine the canonical big data hello world
example: Word Count.

In Storm, you have an incoming source of data, a “spout”, that sentences flow
into. These are handed off to a unit of processing, a “bolt”, that splits the
sentences into words. These words are then sent on to other bolts using
consistent hashing so that all instances of the word ‘foo’ end up at the same
bolt. Within the bolt, we keep a running count of each word seen. Periodically,
we output the count for each word seen to another system. The bolt to jvm
relationship is N to 1. That is, at least 1 or more counting bolts run per JVM.
If our jvm crashes, we lose that state. Our word count will be off. Further, if
a sentence gets replayed due to error, we can end up with inaccurate results.
Not losing our state and not double counting are the hard work of stream
processing that Storm and frameworks of its ilk push off onto the programmer.

Buffy puts our state management and idempotent processing at the core of the
developer experience. (this is not the only way to model our data) With Buffy,
we start with 1 or more idempotent data structures that can store our state. In
the simplest example, we can have a single data structure for all words. This
data structure is a map that in turn contains keys and values. Each key is the
word, and the value is an idempotent counter of the number of times we have
seen the word.

[source,json]
----
all-words : {
  “foo” => 14,
  “bar” => 15
}
----

In our flow, we connect an incoming message source (which gets sentences) to
our data structure with a function that splits those sentences into words and
increments the corresponding counters. Because we are using CRDTs to represent
our map and counters, we can safely concurrently update the messages without
coordination. Further, our data structure is made idempotent so we can
increment its state for the same incoming message multiple times without a
corresponding increase in state. One example way or handling this would be to
store counter state as a tuple of (source_id, increment amount). So if our
counter is:

----
(1, 1)
(2, 4)
(1, 1)
(3, 2)
----

then our final value is 7 because the 1st and 3rd value have a duplicate
source_id and we filter it out. We used message replay to guarantee delivery
and our idempotent data structure to assure accuracy.

We can construct longer data flows by connecting chains of structures together

-> incoming message -> FUNCTION -> data structure

where changes in the state of a given data structure are broadcast out to
interested functions as an incoming message.

==== Querying data

Buffy provides no data querying capabilities. All movement is based on reacting
to changes in state. If an external entity needs to query data in order to run
reports etc, then the final step in a Buffy flow should be to export data to a
queryable store (timeseries db, RDBMS etc). As we are currently imagining Buffy,
there is no internal querying as well. Pure dataflow. It seems likely that we
might relax this for querying reference data etc that would be used and we want
to store on the grid. However, more research needs to go into this and figure
out what it means. For the time being, queryable internal data should be ignored
as it probably won’t be the same idempotent data structures that we are using
elsewhere.

== Buffy: the platform

A streaming data processor itself is great but, to provide customers with a
robust solution, we feel it is important to provide an integrated experience
that includes monitoring and management including a friendly UI.

=== Applications

Multiple data flows/pipelines running on a cluster, possibly sharing steps

=== Monitoring and Management

Buffy will include comprehensive monitoring and management capabilities as well
a level of debugability not available in the alternatives. Monitoring and
management will span the different parts of the platform from the physical
servers to the services that make up the platform to the applications/flows
running on top of the platform. The purpose of the management functionality is
to allow people to easily operate and administer the platform, it’s components,
and the applications running on top.

At the core of monitoring and management is Syntelligence.
Syntelligence is the automated self-healing capability of Buffy. It will use a
combination of machine learning, data correlation, anomaly detection, monitoring
data and event data in order to identify and resolve issues (service crash,
abnormal performance, server crash, etc). We will cover Syntelligence and its
inner working in another document.

Management capabilities include::

* Adding & Removing nodes from the cluster
* Deploy & Remove applications
* Change resource allocation/priority of applications
* View application information including status and metrics
* Rebalance applications after cluster configuration changes

Monitoring capabilities include::

* Server health & metrics
* Component health & metrics
* Application health & metrics
* System event logs such as server up, service started, service shutdown etc
* Syntelligence history & logs

Debugging capabilities include::

* Full message tracing
* Auditing of application state at the time decisions were made

== Next steps

Hopefully by now, you have a decent feel for what we are trying to accomplish
with Buffy. We've glossed over a ton of details in this document and we've left
a variety of ideas out. You should have enough background now to start digging
into more detailed documents about Buffy.
